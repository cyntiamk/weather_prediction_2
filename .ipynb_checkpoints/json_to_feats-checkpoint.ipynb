{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from functools import reduce\n",
    "import time\n",
    "import csv\n",
    "\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_to_c (k):\n",
    "    return k - 273.15\n",
    "\n",
    "# function to calculate temperature dew point\n",
    "#  equation ==> Td = T - ((100 - RH) / 5)\n",
    "\n",
    "def calculate_dp(T, H):\n",
    "    return T - ((100 - H) / 5)\n",
    "\n",
    "# function to create new features based on 3 previous days\n",
    "def new_features(df, feature, N): \n",
    "    # total number of rows\n",
    "    rows = df.shape[0]\n",
    "    # a list representing number of days for prior measurements of feature\n",
    "    # notice that the front of the list needs to be padded with N\n",
    "    # None values to maintain the constistent rows length for each N\n",
    "    numb_days_prior_measurements = [None]*N + [df[feature][i-N] for i in range(N, rows)]\n",
    "    # make a new column name of feature_N and add to DataFrame\n",
    "    col_name = \"{}_{}\".format(feature, N)\n",
    "    df[col_name] = numb_days_prior_measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_class(city_):\n",
    "\n",
    "    connex = sqlite3.connect(\"weather_predict.db\")\n",
    "    cur = connex.cursor()\n",
    "    with open( 'json_files/' + city_ + '_weather.json') as f:\n",
    "        city = json.load(f)\n",
    "\n",
    "    date = []\n",
    "    city_temp = []\n",
    "    city_max = []\n",
    "    city_min = []\n",
    "    city_humidity = []\n",
    "    city_pressure = []\n",
    "    city_wind = []\n",
    "    city_clouds = []\n",
    "    city_desc = []\n",
    "\n",
    "\n",
    "    for measure in city:\n",
    "        date.append(measure['dt_iso'])\n",
    "        city_temp.append(measure['main']['temp'])\n",
    "        city_max.append(measure['main']['temp_max'])\n",
    "        city_min.append(measure['main']['temp_min'])\n",
    "        city_pressure.append(measure['main']['pressure'])\n",
    "        city_humidity.append(measure['main']['humidity'])\n",
    "        city_wind.append(measure['wind']['speed'])\n",
    "        city_clouds.append(measure['clouds']['all'])\n",
    "        city_desc.append(measure['weather'][0]['main'])\n",
    "\n",
    "    # Convert temperature from Kelvin to Celsius\n",
    "    temp_c = []\n",
    "    for k in city_temp:\n",
    "        c = round(k_to_c(k),2)\n",
    "        temp_c.append(c)\n",
    "\n",
    "    temp_max_c = []\n",
    "    for k in city_max:\n",
    "        c = round(k_to_c(k),2)\n",
    "        temp_max_c.append(c)\n",
    "\n",
    "    temp_min_c = []\n",
    "    for k in city_min:\n",
    "        c = round(k_to_c(k),2)\n",
    "        temp_min_c.append(c)\n",
    "\n",
    "    # Calculate dew point\n",
    "    city_dp = []\n",
    "    for T ,H in zip(temp_c, city_humidity):\n",
    "        dp = calculate_dp(T,H)\n",
    "        city_dp.append(dp)\n",
    "\n",
    "    city_max_dp = []\n",
    "    for T ,H in zip(temp_max_c, city_humidity):\n",
    "        dp = calculate_dp(T,H)\n",
    "        city_max_dp.append(dp)\n",
    "\n",
    "    city_min_dp = []\n",
    "    for T ,H in zip(temp_min_c, city_humidity):\n",
    "        dp = calculate_dp(T,H)\n",
    "        city_min_dp.append(dp)\n",
    "\n",
    "    # convert date to show only day without time\n",
    "    city_date = []\n",
    "    for day in date:\n",
    "        timestamp = datetime.strptime(day,'%Y-%m-%d %H:%M:%S +0000 UTC')\n",
    "        day_only = datetime.strftime(timestamp,'%Y-%m-%d')\n",
    "        city_date.append(day_only)\n",
    "\n",
    "    # Create dict to hold all key, values \n",
    "    city_dict = {\n",
    "        \"Date\": city_date,\n",
    "        \"Avg_temp\": temp_c,\n",
    "        \"Temp_max\": temp_max_c,\n",
    "        \"Temp_min\": temp_min_c,\n",
    "        \"Avg_dwp\": city_dp,\n",
    "        \"Max_dwp\": city_max_dp,\n",
    "        \"Min_dwp\": city_min_dp,\n",
    "        \"Pressure\": city_pressure,\n",
    "        \"Humidity\": city_humidity,\n",
    "        \"Wind\": city_wind,\n",
    "        \"Clouds\": city_clouds,\n",
    "        \"Description\": city_desc\n",
    "    }\n",
    "\n",
    "    city_df = pd.DataFrame(city_dict)\n",
    "    grouped_city = city_df.groupby('Date')\n",
    "    city_mean = grouped_city[['Avg_temp','Avg_dwp']].mean()\n",
    "    city_max = grouped_city[['Temp_max','Max_dwp']].max()\n",
    "    city_min= grouped_city[['Temp_min','Min_dwp']].min()\n",
    "\n",
    "    dfs = [city_mean, city_max, city_min]\n",
    "\n",
    "    df_final = reduce(lambda left,right: pd.merge(left,right,on='Date'), dfs)\n",
    "\n",
    "    features_city = ['Avg_temp', 'Avg_dwp', 'Temp_max', 'Max_dwp', 'Temp_min', 'Min_dwp']\n",
    "    #N is the number of days prior to the prediction, 3 days for this model\n",
    "    for feature in features_city:  \n",
    "        if feature != 'Date':\n",
    "            for N in range(1, 4):\n",
    "                new_features(df_final, feature, N)\n",
    "\n",
    "    clean_df = df_final.dropna()\n",
    "    clean_df.to_sql(name=city_+'_train_feats', con=connex, if_exists='replace',index=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "kyoto = 'kyoto'\n",
    "manly = 'manly'\n",
    "nice = 'nice'\n",
    "salvador = 'salvador'\n",
    "kauai = 'kauai'\n",
    "json_to_class(kyoto)\n",
    "json_to_class(manly)\n",
    "json_to_class(nice)\n",
    "json_to_class(salvador)\n",
    "json_to_class(kauai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert Kelvin to Fahrenheit\n",
    "def k_to_c (k):\n",
    "    return k - 273.15\n",
    "\n",
    "# function to calculate temperature dew point\n",
    "#  equation ==> Td = T - ((100 - RH) / 5)\n",
    "\n",
    "def calculate_dp(T, H):\n",
    "    return T - ((100 - H) / 5)\n",
    "\n",
    "# function to create new features based on 3 previous days\n",
    "def new_features(df, feature, N): \n",
    "    # total number of rows\n",
    "    rows = df.shape[0]\n",
    "    # a list representing number of days for prior measurements of feature\n",
    "    # notice that the front of the list needs to be padded with N\n",
    "    # None values to maintain the constistent rows length for each N\n",
    "    numb_days_prior_measurements = [None]*N + [df[feature][i-N] for i in range(N, rows)]\n",
    "    # make a new column name of feature_N and add to DataFrame\n",
    "    col_name = \"{}_{}\".format(feature, N)\n",
    "    df[col_name] = numb_days_prior_measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'kyoto_recent.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-b2dd5efdc379>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'kyoto_recent.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcity_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mday\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcity\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtimestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mday\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'%Y-%m-%d %H:%M:%S'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/PythonData/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/PythonData/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/PythonData/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/PythonData/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/PythonData/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'kyoto_recent.csv' does not exist"
     ]
    }
   ],
   "source": [
    "city = pd.read_csv('kyoto_recent.csv')\n",
    "city_date = []\n",
    "\n",
    "for day in city['Date']:\n",
    "    timestamp = datetime.strptime(day,'%Y-%m-%d %H:%M:%S')\n",
    "    day_only = datetime.strftime(timestamp,'%Y-%m-%d')\n",
    "    city_date.append(day_only)\n",
    "date = pd.DataFrame(city_date)\n",
    "\n",
    "city['Date'] = date.values\n",
    "\n",
    "del city['Unnamed: 0']\n",
    "\n",
    "grouped_city = city.groupby('Date')\n",
    "city_mean = grouped_city[['Mean_temp','Mean_dwp']].mean()\n",
    "city_max = grouped_city[['Max_temp','Max_dwp']].max()\n",
    "city_min= grouped_city[['Min_temp','Min_dwp']].min()\n",
    "\n",
    "dfs = [city_mean, city_max, city_min]\n",
    "\n",
    "df_final = reduce(lambda left,right: pd.merge(left,right,on='Date'), dfs)\n",
    "city_organized = df_final[['Mean_temp','Max_temp','Min_temp','Mean_dwp','Max_dwp','Min_dwp']]\n",
    "city_renamed = city_organized.rename(columns={'Mean_temp': 'Avg_temp','Max_temp': 'Temp_max','Min_temp':'Temp_min',\n",
    "                                       'Mean_dwp': 'Avg_dwp','Max_dwp': 'Max_dwp','Min_dwp': 'Min_dwp'})\n",
    "#features_city = list(city_renamed.columns.values)\n",
    "#N is the number of days prior to the prediction, 3 days for this model\n",
    "#for feature in features_city:  \n",
    " #   if feature != 'Date':\n",
    "  #      for N in range(1, 4):\n",
    "   #         new_features(city_renamed, feature, N)\n",
    "new_index = city_renamed.reset_index()\n",
    "place_holder_row = new_index.append(pd.Series([np.nan]),ignore_index = True)\n",
    "del place_holder_row[0]\n",
    "place_holder_row\n",
    "#city_renamed.to_csv(city_name +'_test_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features_city = list(place_holder_row.columns.values)\n",
    "\n",
    "#N is the number of days prior to the prediction, 3 days for this model\n",
    "for feature in features_city:  \n",
    "    if feature != 'Date':\n",
    "        for N in range(1, 4):\n",
    "            new_features(place_holder_row, feature, N)\n",
    "new_index = place_holder_row.sort_index(ascending=False)\n",
    "most_recent_feat = new_index.reset_index()\n",
    "most_recent_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_recent_feat = place_holder_row.iloc[8,:]\n",
    "most_recent_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numb_days_prior_measurements = [None]*N + [df[feature][i-N] for i in range(N, rows)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numb_days_prior_measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of rows\n",
    "rows = df.shape[0]\n",
    "# a list representing number of days for prior measurements of feature\n",
    "# notice that the front of the list needs to be padded with N\n",
    "# None values to maintain the constistent rows length for each N\n",
    "numb_days_prior_measurements = [None]*N + [df[feature][i-N] for i in range(N, rows)]\n",
    "# make a new column name of feature_N and add to DataFrame\n",
    "col_name = \"{}_{}\".format(feature, N)\n",
    "df[col_name] = numb_days_prior_measurements"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData]",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
